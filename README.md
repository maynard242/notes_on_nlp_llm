# An Eight-Week Intensive Curriculum in Modern Natural Language Processing

This repository contains a comprehensive, eight-week course designed for an AI researcher aiming to build a deep, first-principles understanding of Natural Language Processing (NLP) and Large Language Models (LLMs). The curriculum has been expanded to integrate foundational machine learning concepts and provide a more thorough, logically-paced progression from classical techniques to the state-of-the-art.

This course is structured around key academic papers, lectures, and "The Hundred-Page Language Models Book" by Andriy Burkov, which serves as a core practical text.

## Course Structure

The course is broken down into eight weekly modules. Each week's directory contains a `README.md` file with the core material, primary readings, and key references.

- **[Week 1: Machine Learning & NLP Fundamentals](./week1/)**: A unified introduction to the mathematical and linguistic foundations required for deep learning in NLP.
- **[Week 2: Classical Language Modeling & Representations](./week2/)**: From sparse count vectors to the dawn of dense embeddings with Word2Vec and GloVe.
- **[Week 3: Sequential Processing with Recurrent Neural Networks](./week3/)**: Understanding the architecture and limitations of RNNs and LSTMs, the precursors to modern architectures.
- **[Week 4: The Transformer Architecture](./week4/)**: A deep, mechanical dive into the self-attention mechanism and the components of the Transformer.
- **[Week 5: The Rise of Large Language Models (LLMs)](./week5/)**: Exploring the pre-training paradigms (BERT, GPT, T5) and the scaling laws that enabled them.
- **[Week 6: Fine-Tuning and Adaptation](./week6/)**: Techniques for specializing pre-trained models for specific tasks, focusing on parameter-efficient methods like LoRA.
- **[Week 7: Prompting, Sampling, and In-Context Learning](./week7/)**: Mastering the art and science of interacting with trained LLMs, including prompt engineering and hallucination mitigation.
- **[Week 8: Alignment and Advanced Topics](./week8/)**: The final frontier of aligning models with human values (RLHF, DPO) and a survey of cutting-edge topics like MoE and VLMs.